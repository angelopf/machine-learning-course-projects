{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Ã‚ngelo Pascoal Figueiral, 44645</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "The assignment 3 contains 1 question and the due date is April 18th (Sunday) 23:59PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "We use true financial audit dataset for modelling productive and non-productive audits of a person's financial statement. A productive audit is one which identifies errors or inaccuracies in the information provided by a client. A non-productive audit is usually an audit which found all supplied information to be in order.\n",
    "\n",
    "\n",
    "- Age: The age.\n",
    "- Employment: The type of employment.\n",
    "- Education: The highest level of education.\n",
    "- Marital: Current marital status.\n",
    "- Occupation: The type of occupation.\n",
    "- Income: The amount of income declared.\n",
    "- Gender: The persons gender.\n",
    "- Deductions: Total amount of expenses that a person claims in their financial statement.\n",
    "- Hours: The average hours worked on a weekly basis.\n",
    "- TARGET_Adjusted: This is a numeric field of class integer, but limited to 0 and 1, indicating non-productive and productive audits, respectively. Productive audits are those that result in an adjustment being made to a client's financial statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1.1 (20 points)\n",
    "Read the data from audit.csv. Implement a preprocessing pipeline to separately transform the categorical features `Employment`, `Education`, `Marital`, `Occuptation`, `Gender`, `Deduction` and numeric features `Income` and `Hours`. For categorical features, perform one-hot encoding. For numerical features, perform standardization. For `Age`, build a custom transformer to make the age group feature [17-30, 30-50, 50-83] and then one-hot encode the age group. Report the shape of the transformed train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1519, 9)\n",
      "X_test shape:(380, 9)\n",
      "y_train shape:(1519,)\n",
      "y_test shape:(380,)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "audit = pd.read_csv('audit.csv')\n",
    "audit.head()\n",
    "\n",
    "X, y = audit.loc[:,'Age':'Hours'], audit.loc[:,'Adjusted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f\"X_train shape:{X_train.shape}\\nX_test shape:{X_test.shape}\\ny_train shape:{y_train.shape}\\ny_test shape:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Income</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Deductions</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Age, Employment, Education, Marital, Occupation, Income, Gender, Deductions, Hours, Adjusted]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there are any missing values\n",
    "audit_incomplete_rows = audit[audit.isnull().any(axis=1)]\n",
    "audit_incomplete_rows\n",
    "\n",
    "#there are no missing values, meaning we can proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "num_attribs = ['Income', 'Hours']\n",
    "cat_attribs = ['Employment', 'Education', 'Marital', 'Occupation', 'Gender', 'Deductions']\n",
    "    \n",
    "\n",
    "\n",
    "# creating function to create the bins for the age data\n",
    "def age_bins_creator(col):\n",
    "    ages = pd.DataFrame(data = col, columns = ['Age'])\n",
    "    age_cats = pd.cut(ages[\"Age\"], bins=[17., 30., 50., 83.], right= False, labels=['17-30', '30-50', '50-83'])\n",
    "    age_cats_df = pd.DataFrame(data = age_cats, columns = ['Age'])\n",
    "    return age_cats_df\n",
    "\n",
    "\n",
    "# creating a class to select numerical and categorical columns \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values    \n",
    "    \n",
    "    \n",
    "age_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['Age'])),\n",
    "    ('age_transformer', FunctionTransformer(age_bins_creator, validate = False)),\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('age_enconder', OneHotEncoder(sparse=False,handle_unknown = \"ignore\")),\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False,handle_unknown = \"ignore\")),\n",
    "])\n",
    "\n",
    "pre_processing_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('age_pipeline', age_pipeline),\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "audit_prepared = pre_processing_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring audit_prepared\n",
    "len(audit_prepared[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 (10 points)\n",
    "\n",
    "Now add a LogisticRegression model to the pipeline to fit the train set and report the predictive precision, recall and f1 score on the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('preprocessing', pre_processing_pipeline),\n",
    "    ('lr', log_reg)\n",
    "])\n",
    "\n",
    "model = log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.63\n",
      "Recall: 0.55\n",
      "Precision: 0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "print(f\"\"\"F1_Score: {round(f1_score(y_test, y_pred), 2)}\n",
    "Recall: {round(recall_score(y_test, y_pred), 2)}\n",
    "Precision: {round(precision_score(y_test, y_pred), 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 (20 points)\n",
    "\n",
    "Now use the sklearn.decomposition.PCA to perform principal component analysis on the data and explain which number of principal components should be chosen using Elbow method if PCA reaches 90% threshold of explained variance. Add the PCA to the preprocessing pipeline and use Logistic Regression to fit the train set. Report the predictive precision, recall and f1 score on the test set. Explain whether you would be able to achieve a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components to be used for a 90% threshold of explained variance: 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.9)\n",
    "\n",
    "X_reduced = pca.fit_transform(audit_prepared)\n",
    "\n",
    "print(f\"Number of principal components to be used for a 90% threshold of explained variance: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline = Pipeline([ \n",
    "    ('preprocessing', pre_processing_pipeline),\n",
    "    ('pca', pca),\n",
    "    ('lr', log_reg),\n",
    "])\n",
    "\n",
    "model = pca_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.64\n",
      "Recall: 0.55\n",
      "Precision: 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "print(f\"\"\"F1_Score: {round(f1_score(y_test, y_pred), 2)}\n",
    "Recall: {round(recall_score(y_test, y_pred), 2)}\n",
    "Precision: {round(precision_score(y_test, y_pred), 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "- Adding Principal Component Analysis to the pipeline improved the model very slightly. In fact, the increase is so small that it is unclear whether PCA actually improves the model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4 (10 points)\n",
    "\n",
    "Now fine-tune the n_compnents from 1 to 50 in the pca using a grid search strategy through 5-fold cross-validation (with the f1 as the scoring function). Plot the `mean test score` for grid searched n_components. Expalin whether the best estimator obtained from fine-tuning process is the same n_components from the previous question. Also, report predictive precision, recall and f1 score on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Grid Search fine-tuning: {'pca__n_components': 19}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': range(1,50),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pca_pipeline, param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"After Grid Search fine-tuning: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = grid_search.cv_results_['mean_test_score']\n",
    "x_axis = range(1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bde5c08430>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_axis, y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.63\n",
      "Recall: 0.53\n",
      "Precision: 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "print(f\"\"\"F1_Score: {round(f1_score(y_test, y_pred), 2)}\n",
    "Recall: {round(recall_score(y_test, y_pred), 2)}\n",
    "Precision: {round(precision_score(y_test, y_pred), 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "- After fine-tuning, the number of principal components decreased by 1 (from 20 in 1.3 to 19 after fine-tuning).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5 (10 points) \n",
    "Add the PCA transformed features to the preprocessing pipeline, fine-tune again the n_components and report the best estimator obtained same as above. In other words, both the preprocessed features and PCA-processed features will be concatenated togehter. Explain whether adding PCA transformed feature would help increase model performance. Also, report predictive precision, recall and f1 score on the test set. (Hint: use FeatureUnion to concatenate the features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['Age'])),\n",
    "    ('age_transformer', FunctionTransformer(age_bins_creator, validate = False)),\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('age_enconder', OneHotEncoder(sparse=False,handle_unknown = \"ignore\")),\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False,handle_unknown = \"ignore\")),\n",
    "])\n",
    "\n",
    "pre_processing_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('age_pipeline', age_pipeline),\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "pca_pipeline = Pipeline([ \n",
    "    ('preprocessing', pre_processing_pipeline),\n",
    "    ('pca', pca),\n",
    "])\n",
    "\n",
    "concatenated_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('pre_processing_pipeline', pre_processing_pipeline),\n",
    "    ('pca_pipeline', pca_pipeline),\n",
    "    ])\n",
    "\n",
    "\n",
    "audit_prepared = concatenated_pipeline.fit_transform(X)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=0.9)\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "model_pipeline = Pipeline([ \n",
    "    ('concatenated_pipeline', concatenated_pipeline),\n",
    "    ('lr', log_reg),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1899, 72)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Grid Search fine-tuning: {'concatenated_pipeline__pca_pipeline__pca__n_components': 29}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'concatenated_pipeline__pca_pipeline__pca__n_components': range(1,50),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"After Grid Search fine-tuning: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideal number of principal components increased by 9 from the previous method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.63\n",
      "Recall: 0.55\n",
      "Precision: 0.73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(f\"\"\"F1_Score: {round(f1_score(y_test, y_pred), 2)}\n",
    "Recall: {round(recall_score(y_test, y_pred), 2)}\n",
    "Precision: {round(precision_score(y_test, y_pred), 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "- In this case, GridSearchCV returns an optimal number of features of 29.\n",
    "- When considereing the difference in recall, precision, and F1 scores, we can conclude that this does not improve our model.\n",
    "\n",
    "- Moreover, adding the PCA features will result in a more complex and slower model without adding anything in return.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.6 (20 points)\n",
    "\n",
    "Now build a pipeline with the stacking model as the last step that takes the random forest, adaboost, gradient boost and KNN models as the base estimator and Logistic regression as the final estimator. Fine-tune the model using the hyperparameters for all these models and report the predicted precision, recall and f1 score on test set (you should be able to achieve comparable performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier, \\\n",
    "                            GradientBoostingClassifier, StackingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ada_boost_pipeline = make_pipeline(concatenated_pipeline,\n",
    "                               AdaBoostClassifier())\n",
    "\n",
    "rf_pipeline = make_pipeline(concatenated_pipeline,\n",
    "                            RandomForestClassifier(random_state=0))\n",
    "\n",
    "gradient_pipeline = make_pipeline(\n",
    "    concatenated_pipeline,\n",
    "    GradientBoostingClassifier())\n",
    "\n",
    "knn_pipeline = make_pipeline(\n",
    "    concatenated_pipeline,\n",
    "    KNeighborsClassifier())\n",
    "\n",
    "estimators = [('rf', rf_pipeline),\n",
    "              ('ada_boost', ada_boost_pipeline),\n",
    "              ('Gradient Boosting', gradient_pipeline),\n",
    "             ('knn', knn_pipeline)]\n",
    "\n",
    "stacking_regressor = StackingRegressor(estimators=estimators,\n",
    "                                       final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "estimators = [\n",
    "    ('ada_boost', AdaBoostClassifier()),\n",
    "    ('rf', RandomForestClassifier(random_state=0)),\n",
    "    ('gradient', GradientBoostingClassifier(random_state=0)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator= LogisticRegression(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['Age'])),\n",
    "    ('age_transformer', FunctionTransformer(age_bins_creator, validate = False)),\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('age_enconder', OneHotEncoder(sparse=False,handle_unknown = \"ignore\")),\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    \n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False,handle_unknown = \"ignore\")),\n",
    "])\n",
    "\n",
    "pre_processing_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('age_pipeline', age_pipeline),\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('pre_processing_pipeline', concatenated_pipeline),\n",
    "    ('reg', stacking),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'reg__rf__n_estimators': range(1,5),\n",
    "    'reg__ada_boost__n_estimators': range(1,5),\n",
    "    'reg__gradient__n_estimators': range(1,5),\n",
    "    'reg__knn__n_neighbors': range(1,5),\n",
    "}\n",
    "# wider ranges should have been used, but running that took too much time\n",
    "\n",
    "grid = GridSearchCV(final_pipeline, param_grid=params, scoring='f1',cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg__ada_boost__n_estimators': 1, 'reg__gradient__n_estimators': 4, 'reg__knn__n_neighbors': 4, 'reg__rf__n_estimators': 3}\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.7 (10 points)\n",
    "Once the final model is obtained, export the model as a pickle, and show you can make the predictions on the following observations without having to retrain (you should expect to get the predicted value of 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Income</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Deductions</th>\n",
       "      <th>Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>College</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Support</td>\n",
       "      <td>125370</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Employment Education   Marital Occupation  Income  Gender  Deductions  \\\n",
       "0   45    Private   College  Divorced    Support  125370  Female       False   \n",
       "\n",
       "   Hours  \n",
       "0     40  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_news = pd.DataFrame({\n",
    "    'Age': 45,\n",
    "    'Employment': 'Private',\n",
    "    'Education': 'College',\n",
    "    'Marital': 'Divorced',\n",
    "    'Occupation': 'Support',\n",
    "    'Income': 125370,\n",
    "    'Gender': 'Female',\n",
    "    'Deductions': False,\n",
    "    'Hours': 40}, index=[0])\n",
    "X_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model through Pickle\n",
    "import pickle\n",
    "\n",
    "pickled_model = grid.best_estimator_\n",
    "\n",
    "with open(\"pickled_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pickled_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the model\n",
    "my_pipeline = pickle.load(open(\"pickled_model.pkl\",\"rb\"))\n",
    "\n",
    "final_predictions = my_pipeline.predict(X_news)\n",
    "\n",
    "final_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
